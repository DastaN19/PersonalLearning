{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f93bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing basic packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bbc92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-2.0.7-py2.py3-none-any.whl (26 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\91870\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 flatbuffers-2.0.7 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.1 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a829ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# basic packages for deep learning\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082dcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9790b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_boston(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d717dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9cd459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c987970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "419a7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "408f1fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  24.0\n",
       "1  21.6\n",
       "2  34.7\n",
       "3  33.4\n",
       "4  36.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed9c18",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f67373de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarisation\n",
    "# normalization\n",
    "# Min_Max approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448d8c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc_x = sc.fit_transform(X)\n",
    "sc_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ca4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(sc_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d86111b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "         7         8         9         10        11        12  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f246bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(127, 13)\n",
      "(379, 1)\n",
      "(127, 1)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data into train test \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state=1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee28d37b",
   "metadata": {},
   "source": [
    "## Deep Learning - Neural Networks\n",
    "\n",
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a647ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "147a159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Layer connected with hidden layers\n",
    "\n",
    "DNN.add(tf.keras.layers.Dense(units=6,activation='relu'))\n",
    "DNN.add(tf.keras.layers.Dense(units=6,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bff38a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "DNN.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7297a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply optimization techniques\n",
    "\n",
    "DNN.compile(optimizer='adam',loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25e07ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 2s 3ms/step - loss: 604.6661\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 599.9998\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 596.1340\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 592.6525\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 589.7408\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 587.1799\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 584.9402\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 582.8874\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 581.0703\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 579.4208\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.8748\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 576.4960\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 575.2681\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 574.1832\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.1777\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 572.2833\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 571.4419\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 570.6613\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 569.9256\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 569.2151\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 568.5513\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 567.9021\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 567.2888\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 566.7001\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 566.1086\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 565.5514\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 564.9957\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 564.4405\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 563.8918\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 563.3472\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 562.8036\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 562.2621\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 561.7297\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 561.1967\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 560.6684\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 560.1374\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 559.6053\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 559.0821\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 558.5621\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 558.0353\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 557.5101\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 556.9895\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 556.4667\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 555.9466\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 555.4290\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 554.9091\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 554.3878\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 553.8738\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 553.3542\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 552.8370\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 552.3216\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 551.8090\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 551.2916\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 550.7771\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 550.2653\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 549.7566\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 549.2409\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 548.7300\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 548.2183\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 547.7095\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 547.1934\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 546.6878\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 546.1796\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 545.6645\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 545.1589\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 544.6517\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 544.1424\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 543.6289\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 543.1284\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 542.6202\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 542.1132\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 541.6069\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 541.0988\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 540.5939\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 540.0908\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 539.5880\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 539.0817\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 538.5801\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 538.0751\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 537.5728\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 537.0685\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 536.5674\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 536.0677\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 535.5684\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 535.0641\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 534.5615\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 534.0620\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 533.5646\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 533.0660\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 532.5641\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 532.0653\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 531.5668\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 531.0716\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 530.5712\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 530.0726\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 529.5767\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 529.0816\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 528.5841\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 528.0941\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 527.5880\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 527.0981\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 526.6024\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 526.1104\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 525.6161\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 525.1219\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 524.6274\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 524.1322\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 523.6386\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 523.1497\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 522.6574\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 522.1644\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 521.6746\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 521.1799\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 520.6938\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 520.2029\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 519.7104\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 519.2231\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 518.7320\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 518.2449\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 517.7577\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 517.2676\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 516.7779\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 516.2932\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 515.8047\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 515.3179\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 514.8337\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 514.3426\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 513.8666\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 513.3747\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 512.8854\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 512.4044\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 511.9214\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 511.4330\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 510.9532\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 510.4633\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 509.9845\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 509.5032\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 509.0179\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 508.5370\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 508.0545\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 507.5757\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 507.0952\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 506.6122\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 506.1306\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 505.6552\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 505.1755\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 504.6966\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 504.2173\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 503.7357\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 503.2581\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 502.7855\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 502.3006\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 501.8288\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 501.3499\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 500.8701\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 500.3983\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 499.9236\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 499.4459\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 498.9736\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 498.4932\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 498.0173\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 497.5478\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 497.0754\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 496.6015\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 496.1251\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 495.6511\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 495.1787\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 494.7116\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 494.2374\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 493.7633\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 493.2947\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 492.8239\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 492.3521\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 491.8795\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 491.4130\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 490.9414\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 490.4746\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 490.0014\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 489.5348\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 489.0670\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 488.5993\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 488.1300\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 487.6624\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 487.1955\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 486.7267\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 486.2592\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 485.7945\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 485.3296\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 484.8634\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 484.3982\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 483.9307\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 483.4671\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 482.9991\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 482.5398\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 482.0756\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 481.6100\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 481.1494\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 480.6860\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 480.2219\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 479.7615\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 479.3013\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 478.8370\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 478.3774\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 477.9152\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 477.4536\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 476.9947\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 476.5331\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 476.0759\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 475.6196\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 475.1533\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 474.6975\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 474.2385\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 473.7798\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 473.3245\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 472.8697\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 472.4094\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 471.9517\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 471.4966\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 471.0380\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 470.5858\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 470.1306\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 469.6725\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 469.2185\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 468.7646\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 468.3085\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 467.8577\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 467.4041\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.9468\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 466.4974\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 466.0423\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 465.5930\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 465.1399\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 464.6892\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 464.2361\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 463.7863\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 463.3329\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 462.8839\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 462.4361\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 461.9824\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 461.5366\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 461.0874\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 460.6370\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 460.1893\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 459.7372\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 459.2922\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 458.8436\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 458.3938\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 457.9478\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 457.5004\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 457.0528\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 456.6093\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 456.1624\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 455.7162\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 455.2737\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 454.8257\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 454.3828\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 453.9395\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 453.4925\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 453.0511\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 452.6066\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 452.1630\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 451.7196\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 451.2784\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 450.8346\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 450.3917\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 449.9507\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 449.5096\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 449.0693\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 448.6296\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 448.1874\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 447.7450\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 447.3087\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 446.8703\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 446.4285\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 445.9897\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 445.5512\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 445.1138\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 444.6744\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 444.2436\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 443.7948\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 443.3655\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 442.9273\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 442.4888\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 442.0507\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 441.6177\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 441.1804\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 440.7408\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 440.3080\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 439.8742\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 439.4426\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 439.0024\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 438.5726\n",
      "Epoch 293/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 438.1366\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 437.7002\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 437.2698\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 436.8392\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 436.4064\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 435.9701\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 435.5417\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 435.1087\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 434.6770\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 434.2466\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 433.8193\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 433.3856\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 432.9586\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 432.5266\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 432.0954\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 431.6676\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 431.2408\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430.8092\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430.3807\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429.9575\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429.5284\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429.0945\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428.6720\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428.2423\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427.8134\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427.3907\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426.9631\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426.5378\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426.1121\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425.6868\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425.2611\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424.8383\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424.4124\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 423.9852\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 423.5664\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 423.1380\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 422.7190\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 422.2928\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421.8728\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421.4463\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421.0254\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420.6072\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420.1818\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 419.7610\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 419.3407\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 418.9213\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 418.5009\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 418.0805\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 417.6581\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 417.2410\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 416.8227\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 416.4014\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 415.9836\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 415.5654\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 415.1481\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 414.7305\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 414.3076\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 413.8954\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 413.4809\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 413.0603\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 412.6435\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 412.2314\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 411.8150\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 411.3983\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 410.9821\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 410.5720\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 410.1546\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 409.7404\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 409.3267\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.9115\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 408.4995\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 408.0854\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 407.6693\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 407.2615\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 406.8493\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 406.4324\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 406.0222\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 405.6123\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 405.1988\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 404.7891\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 404.3783\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 403.9664\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 403.5581\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 403.1491\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 402.7388\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 402.3264\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 401.9268\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 401.5101\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 401.1061\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 400.6967\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 400.2899\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 399.8831\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 399.4765\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 399.0667\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 398.6600\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 398.2576\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 397.8459\n",
      "Epoch 390/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 397.4440\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 397.0379\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 396.6315\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 396.2292\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 395.8240\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 395.4148\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 395.0188\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 394.6072\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 394.2069\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 393.8002\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 393.3997\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 392.9983\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 392.5952\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 392.1905\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 391.7958\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 391.3865\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 390.9893\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 390.5830\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 390.1838\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 389.7841\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 389.3858\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 388.9843\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 388.5868\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 388.1810\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 387.7904\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 387.3872\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 386.9911\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 386.5907\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 386.1965\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 385.7969\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 385.3981\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 385.0058\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 384.6072\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 384.2140\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 383.8118\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 383.4174\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 383.0244\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 382.6238\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 382.2352\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 381.8379\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 381.4408\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 381.0486\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 380.6538\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 380.2617\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 379.8704\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 379.4756\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 379.0813\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 378.6919\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 378.2986\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 377.9069\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 377.5139\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 377.1214\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 376.7347\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 376.3414\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 375.9510\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 375.5589\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 375.1689\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 374.7788\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 374.3897\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 374.0040\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 373.6117\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 373.2228\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 372.8330\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 372.4438\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 372.0612\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 371.6704\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 371.2870\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 370.8939\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 370.5131\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 370.1216\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 369.7392\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 369.3510\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 368.9666\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 368.5826\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 368.1936\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 367.8120\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 367.4253\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 367.0398\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 366.6565\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 366.2768\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.8889\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.5054\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 365.1210\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 364.7386\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 364.3588\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 363.9723\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 363.5910\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 363.2129\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 362.8297\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 362.4449\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 362.0674\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 361.6898\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 361.3058\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 360.9241\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 360.5481\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 360.1676\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 359.7890\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 359.4078\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 359.0325\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 358.6512\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 358.2744\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 357.8961\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 357.5222\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 357.1394\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 356.7674\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 356.3924\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 356.0119\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 355.6372\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 355.2635\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 354.8885\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 354.5103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219562c9100>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying imput dataset along with back propagation\n",
    "\n",
    "DNN.fit(x_train,y_train, batch_size = 32,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4465dd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 354.1330\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 353.7624\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 353.3860\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 353.0114\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 352.6392\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 352.2648\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 351.8905\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 351.5149\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 351.1451\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 350.7752\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 350.3973\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 350.0266\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 349.6556\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 349.2841\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 348.9131\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 348.5420\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 348.1740\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 347.8014\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 347.4309\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 347.0627\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 346.6918\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 346.3260\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 345.9570\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 345.5832\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 345.2175\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 344.8506\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 344.4797\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 344.1118\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 343.7512\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 343.3806\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 343.0141\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 342.6474\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 342.2810\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 341.9129\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 341.5492\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 341.1890\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 340.8177\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 340.4545\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 340.0873\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 339.7236\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 339.3593\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 339.0015\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 338.6292\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 338.2687\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 337.9034\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 337.5441\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 337.1815\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 336.8186\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 336.4596\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 336.0890\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 335.7306\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 335.3731\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 335.0154\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 334.6515\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 334.2926\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 333.9315\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 333.5734\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 333.2128\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 332.8551\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 332.4941\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 332.1373\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 331.7816\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 331.4200\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 331.0634\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 330.7077\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 330.3479\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 329.9868\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 329.6381\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 329.2783\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 328.9203\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 328.5688\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 328.2084\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 327.8559\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 327.4983\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 327.1460\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 326.7911\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 326.4346\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 326.0812\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 325.7256\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 325.3719\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 325.0244\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 324.6685\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 324.3144\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 323.9636\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 323.6089\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 323.2588\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 322.9052\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 322.5590\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 322.2008\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 321.8529\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 321.5003\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 321.1518\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 320.8064\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 320.4511\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 320.1029\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 319.7534\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 319.4049\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 319.0526\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 318.7090\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 318.3579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x219576f8a00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN.fit(x_train,y_train, batch_size = 32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29e567b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n",
      "        0\n",
      "307  28.2\n",
      "343  23.9\n",
      "47   16.6\n",
      "67   22.0\n",
      "362  20.8\n",
      "..    ...\n",
      "41   26.6\n",
      "361  19.9\n",
      "289  24.8\n",
      "498  21.2\n",
      "293  23.9\n",
      "\n",
      "[127 rows x 1 columns]\n",
      "****************************************\n",
      "[[6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.831446 ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.8303676]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.8354826]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.8857374]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]\n",
      " [6.89156  ]]\n"
     ]
    }
   ],
   "source": [
    "# predicting test data with training model\n",
    "\n",
    "y_pred = DNN.predict(x_test)\n",
    "print(y_test)\n",
    "print('**'*20)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694286c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
